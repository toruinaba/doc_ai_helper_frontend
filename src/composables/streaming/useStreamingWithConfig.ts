import { type Ref } from 'vue'
import { useDocumentStore } from '@/stores/document.store'
import { llmService } from '@/services/api/llm.service'
import { getDefaultRepositoryConfig } from '@/utils/config.util'
import type { ClientMessage } from '@/composables/useMessageManagement'

export interface DocumentContextConfig {
  enableRepositoryContext?: boolean
  enableDocumentMetadata?: boolean
  includeDocumentInSystemPrompt?: boolean
  systemPromptTemplate?: string
}

export interface StreamingWithConfigOperations {
  sendStreamingMessageWithConfig: (content: string, config?: Partial<DocumentContextConfig>) => Promise<void>
}

export function useStreamingWithConfig(
  messages: Ref<ClientMessage[]>,
  addUserMessage: (content: string) => ClientMessage,
  addAssistantMessage: (content: string) => ClientMessage,
  addSystemMessage: (content: string) => ClientMessage
): StreamingWithConfigOperations {
  const documentStore = useDocumentStore()

  // æ–°ã—ã„ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ä»•æ§˜ã«å¯¾å¿œã—ãŸã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡
  async function sendStreamingMessageWithConfig(content: string, config?: Partial<DocumentContextConfig>) {
    console.log('Start sending streaming message with config:', content, config)
    
    try {
      // ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
      addUserMessage(content)
      
      // ç¾åœ¨ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
      const currentDoc = documentStore.currentDocument
      
      if (!currentDoc) {
        throw new Error('ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“')
      }
      
      // ãƒªãƒã‚¸ãƒˆãƒªæƒ…å ±ã‚’å–å¾— (ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã®å€¤ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ã—ã€ãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨)
      const defaultConfig = getDefaultRepositoryConfig()
      const service = documentStore.currentService || defaultConfig.service
      const owner = documentStore.currentOwner || defaultConfig.owner
      const repo = documentStore.currentRepo || defaultConfig.repo
      const path = documentStore.currentPath || defaultConfig.path
      const ref = documentStore.currentRef || defaultConfig.ref
      
      // è¨­å®šã®çµ±åˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸ï¼‰
      const effectiveConfig = {
        enableRepositoryContext: config?.enableRepositoryContext ?? true,
        enableDocumentMetadata: config?.enableDocumentMetadata ?? true,
        includeDocumentInSystemPrompt: config?.includeDocumentInSystemPrompt ?? true,
        systemPromptTemplate: config?.systemPromptTemplate ?? 'contextual_document_assistant_ja'
      }
      
      // ä¼šè©±å±¥æ­´ã®æº–å‚™ï¼ˆã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’APIã®å½¢å¼ã«å¤‰æ›ï¼‰
      const conversationHistory = messages.value.map(msg => ({
        role: msg.role,
        content: msg.content,
        timestamp: msg.timestamp.toISOString()
      }))
      
      console.log('ğŸ“¤ Sending message request with new backend specification')
      
      // æ–°ã—ã„çµ±ä¸€ã‚µãƒ¼ãƒ“ã‚¹ã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡
      const response = await llmService.query({
        prompt: content,
        provider: 'openai',
        conversationHistory,
        includeDocument: true
      }, currentDoc)
      
      // ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å‡¦ç†
      if (response.content) {
        addAssistantMessage(response.content)
        
        // ä¼šè©±å±¥æ­´ã®æœ€é©åŒ–ãŒã‚ã£ãŸå ´åˆã¯é©ç”¨
        if (response.optimized_conversation_history && response.optimized_conversation_history.length > 0) {
          console.log('ğŸ—‚ï¸ Server provided optimized conversation history:', 
            response.optimized_conversation_history.length, 'messages')
        }
      }
      
      console.log('Message sent successfully with new specification')
      
    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : 'Unknown error occurred'
      console.error('Error sending message with config:', err)
      
      // ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
      addSystemMessage(`ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ${errorMessage}`)
    }
  }

  return {
    sendStreamingMessageWithConfig
  }
}