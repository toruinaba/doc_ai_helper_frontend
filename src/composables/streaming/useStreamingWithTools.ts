import { ref, type Ref } from 'vue'
import type { components } from '@/services/api/types.auto'
import { useDocumentStore } from '@/stores/document.store'
import { llmService } from '@/services/api/llm.service'
import { getLLMConfig } from '@/utils/config.util'
import type { ClientMessage } from '@/composables/useMessageManagement'
import type { DocumentContextConfig } from './useStreamingWithConfig'

type MessageItem = components['schemas']['MessageItem']

export interface StreamingWithToolsOperations {
  isStreamingWithTools: Ref<boolean>
  currentStreamController: Ref<AbortController | (() => void) | null>
  sendStreamingMessageWithToolsAndConfig: (
    content: string, 
    config?: Partial<DocumentContextConfig>,
    onToken?: (token: string) => void,
    forceToolChoice?: string
  ) => Promise<void>
  stopStreaming: () => void
}

export function useStreamingWithTools(
  messages: Ref<ClientMessage[]>,
  addUserMessage: (content: string) => ClientMessage,
  addAssistantMessage: (content: string) => ClientMessage,
  addSystemMessage: (content: string) => ClientMessage,
  getConversationHistory: () => any[],
  mcpToolsConfig: Ref<any>,
  shouldUseMCPTools: (content: string, autoDetect: boolean) => { recommended: boolean; reasons: string[] },
  activeToolExecutions: Ref<any[]>,
  startToolExecution: (toolCall: any) => any,
  updateToolExecutionStatus: (executionId: string, status: 'pending' | 'running' | 'completed' | 'error', result?: any, error?: string, progress?: number) => void
): StreamingWithToolsOperations {
  const documentStore = useDocumentStore()
  const llmConfig = getLLMConfig()
  
  const isStreamingWithTools = ref(false)
  const currentStreamController = ref<AbortController | (() => void) | null>(null)

  // æ–°ã—ã„ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ä»•æ§˜ã«å¯¾å¿œã—ãŸMCPãƒ„ãƒ¼ãƒ«ä»˜ãã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡
  async function sendStreamingMessageWithToolsAndConfig(
    content: string, 
    config?: Partial<DocumentContextConfig>,
    onToken?: (token: string) => void,
    forceToolChoice?: string
  ) {
    console.log('Start streaming message with MCP tools and config:', content, config)
    isStreamingWithTools.value = true
    
    // å‰ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãŒã‚ã‚Œã°ä¸­æ­¢
    if (currentStreamController.value) {
      if (typeof currentStreamController.value === 'function') {
        currentStreamController.value()
      } else {
        currentStreamController.value.abort()
      }
    }
    
    try {
      // ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
      const userMessage = addUserMessage(content)
      
      // è¨­å®šã¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ãƒãƒ¼ã‚¸
      const effectiveConfig = {
        includeDocumentInSystemPrompt: true,
        systemPromptTemplate: 'contextual_document_assistant_ja',
        enableRepositoryContext: true,
        enableDocumentMetadata: true,
        completeToolFlow: true,
        ...config
      }
      
      console.log('ğŸ“‹ Streaming MCP tools with document context config:', effectiveConfig)
      
      // ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã®åˆ¤å®š
      const toolRecommendation = shouldUseMCPTools(content, mcpToolsConfig.value.autoDetect)
      const useTools = mcpToolsConfig.value.enabled && toolRecommendation.recommended
      
      // executionModeã«åŸºã¥ã„ã¦toolChoiceã‚’è¨­å®š
      let toolChoice: string
      if (forceToolChoice) {
        toolChoice = forceToolChoice
      } else if (useTools) {
        // MCPãƒ„ãƒ¼ãƒ«ãŒæœ‰åŠ¹ãªå ´åˆã¯ã€toolChoiceã‚’ä½¿ç”¨ï¼ˆ'auto', 'none', 'required', ã¾ãŸã¯ç‰¹å®šã®ãƒ„ãƒ¼ãƒ«åï¼‰
        toolChoice = mcpToolsConfig.value.toolChoice
      } else {
        toolChoice = 'none'
      }
      
      console.log('Streaming with tools - Tool recommendation:', toolRecommendation)
      console.log('Using tools:', useTools, 'Tool choice:', toolChoice)
      
      // ç¾åœ¨ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
      const currentDoc = documentStore.currentDocument
      
      if (!currentDoc) {
        throw new Error('ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“')
      }
      
      // ä¼šè©±å±¥æ­´ã‚’æ§‹ç¯‰ï¼ˆæœ€é©åŒ–å±¥æ­´ã‚’å„ªå…ˆä½¿ç”¨ï¼‰
      const conversationHistory = getConversationHistory()
      
      // æ–°ã—ã„ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ä»•æ§˜ã«åˆã‚ã›ãŸå‡¦ç†ã‚’é–‹å§‹
      console.log('ğŸŒŠğŸ› ï¸ Preparing streaming MCP tools request:', {
        useTools,
        toolChoice
      })
      
      // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ
      const assistantMessage = addAssistantMessage('')
      let accumulatedContent = ''
      
      // æ–°ã—ã„çµ±ä¸€ã‚µãƒ¼ãƒ“ã‚¹ã§ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
      await llmService.stream(
        {
          prompt: content,
          provider: llmConfig.defaultProvider,
          model: llmConfig.defaultModel,
          conversationHistory,
          includeDocument: true,
          enableTools: useTools,
          toolChoice,
          completeToolFlow: true
        },
        currentDoc,
        {
          onStart: () => {
            console.log('ğŸš€ MCP tools streaming started')
          },
          onChunk: (chunk) => {
            console.log('ğŸ¯ MCP tools chunk received:', chunk)
            accumulatedContent += chunk
            
            // ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ›´æ–°
            const messageIndex = messages.value.findIndex(m => m.id === assistantMessage.id)
            if (messageIndex !== -1) {
              messages.value[messageIndex] = {
                ...messages.value[messageIndex],
                content: accumulatedContent
              }
            }
            
            // å¤–éƒ¨ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ãŒã‚ã‚Œã°å‘¼ã³å‡ºã—
            onToken?.(chunk)
          },
          onToolCall: (toolCall: any) => {
            console.log('ğŸ› ï¸ Tool call detected during streaming:', toolCall)
            const execution = startToolExecution(toolCall)
            updateToolExecutionStatus(execution.id, 'running')
          },
          onToolResult: (result: any) => {
            console.log('ğŸ¯ Tool result received during streaming:', result)
            
            // å¯¾å¿œã™ã‚‹ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚’å®Œäº†çŠ¶æ…‹ã«æ›´æ–°
            const execution = activeToolExecutions.value.find(exec => 
              exec.toolCall.function.name === result.function_name
            )
            if (execution) {
              updateToolExecutionStatus(execution.id, 'completed', result)
            }
          },
          onError: (error) => {
            console.error('ğŸš¨ MCP tools streaming error:', error)
            const errorMsg = error.message || 'Unknown streaming error'
            addSystemMessage(`MCPãƒ„ãƒ¼ãƒ«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: ${errorMsg}`)
            isStreamingWithTools.value = false
          },
          onEnd: (data) => {
            console.log('âœ… MCP tools streaming ended')
            console.log('Final accumulated content:', accumulatedContent)
            
            // ä¼šè©±å±¥æ­´ã®æœ€é©åŒ–ãŒã‚ã£ãŸå ´åˆã¯é©ç”¨
            if (data?.optimized_conversation_history && data.optimized_conversation_history.length > 0) {
              console.log('ğŸ—‚ï¸ Server provided optimized conversation history for MCP tools streaming:', 
                data.optimized_conversation_history.length, 'messages')
            }
            
            isStreamingWithTools.value = false
          }
        }
      )
      
      console.log('MCP tools streaming message sent successfully')
      
    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : 'Unknown error occurred'
      console.error('Error sending streaming message with MCP tools and config:', err)
      
      // ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
      addSystemMessage(`MCPãƒ„ãƒ¼ãƒ«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ${errorMessage}`)
      isStreamingWithTools.value = false
    }
  }

  // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’åœæ­¢
  function stopStreaming() {
    if (currentStreamController.value) {
      if (typeof currentStreamController.value === 'function') {
        currentStreamController.value()
      } else {
        currentStreamController.value.abort()
      }
      currentStreamController.value = null
    }
    isStreamingWithTools.value = false
  }

  return {
    isStreamingWithTools,
    currentStreamController,
    sendStreamingMessageWithToolsAndConfig,
    stopStreaming
  }
}